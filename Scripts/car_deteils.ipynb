{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openvino.inference_engine import IECore\n",
    "import easyocr \n",
    "ie  = IECore()\n",
    "image_path = r'data_images\\facts-of-seatbelt-4-293a.jpg'\n",
    "Video_path = r'data_videos\\seat_Belts\\gettyimages-900770748-640_adpp.mp4'\n",
    "image = cv2.imread(image_path)\n",
    "def show(image):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "def Slope(a,b,c,d):\n",
    "    return abs(int(d-b)/(c-a))\n",
    "\n",
    "video = cv2.VideoCapture(Video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seat Bealt Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(Video_path)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "            break\n",
    "    frame_1 = frame.copy()\n",
    "    cv2.imshow('video',frame_1)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_black_color(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Thresholding: Set black pixels to white and other pixels to black\n",
    "        _, thresholded = cv2.threshold(gray_frame, 10, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Apply bitwise operation to set thresholded black pixels to white in the original color frame\n",
    "        result = cv2.bitwise_and(frame, frame, mask=thresholded)\n",
    "\n",
    "        cv2.imshow('Black Color Extraction', result)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "extract_black_color(Video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bealt(Video_path):\n",
    "    cap = cv2.VideoCapture(Video_path)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        frame_1 = frame.copy()\n",
    "        labe = ''\n",
    "        image = cv2.resize(frame_1, (600, 800))\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        belt = False\n",
    "        \n",
    "        blur = cv2.blur(gray_image, (1, 1))\n",
    "        edge = cv2.Canny(blur, 50, 400)\n",
    "        ps = 0\n",
    "        px1, py1, px2, py2 = 0, 0, 0, 0\n",
    "        lines = cv2.HoughLinesP(edge, 1, np.pi/270, 30, maxLineGap=20, minLineLength=170)\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                # Slope Of Current Line\n",
    "                if (x2 - x1) == 0:\n",
    "                    s = 0\n",
    "                else:\n",
    "                    s = Slope(x1, y1, x2, y2)\n",
    "\n",
    "                # If Current Line's Slope Is Greater Than 0.7 And Less Than 2\n",
    "                if 0.7 < s < 4:\n",
    "                    # And Previous Line's Slope Is Within 0.7 To 2\n",
    "                    if 0.7 < ps < 4:\n",
    "                        # And Both The Lines Are Not Too Far From Each Other\n",
    "                        if (x1 - px1) > 0.2 and (x2 - px2) > 0.2 or (y1 - py1) > 0.2 and (y2 - py2) > 0.2:\n",
    "                            # Plot The Lines On \"beltframe\"\n",
    "                            cv2.line(frame_1, (x1, y1), (x2, y2), (0, 0, 255), 3)\n",
    "                            cv2.line(frame_1, (px1, py1), (px2, py2), (0, 0, 255), 3)\n",
    "\n",
    "                            # Belt Is Detected\n",
    "                            \n",
    "                            show(frame)\n",
    "                            belt = True\n",
    "\n",
    "                # Otherwise, Current Slope Becomes Previous Slope (ps),\n",
    "                # and Current Line Becomes Previous Line (px1, py1, px2, py2)\n",
    "                ps = s\n",
    "                px1, py1, px2, py2 = line[0]\n",
    "\n",
    "        if belt:\n",
    "            label = 'Seat Belt Detected'\n",
    "        else:\n",
    "            label = 'No Seat Belt Detected'\n",
    "\n",
    "        cv2.putText(frame_1, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        frame_1 = cv2.resize(frame_1, (frame.shape[1], frame.shape[0]))\n",
    "        cv2.imshow('Video', frame_1)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bealt(Video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_license_plates(video_path):\n",
    "    license_plate_xml = r'models\\vehicle-license-plate-detection-barrier-0106\\vehicle-license-plate-detection-barrier-0106.xml'\n",
    "    license_plate_bin = r'models\\vehicle-license-plate-detection-barrier-0106\\vehicle-license-plate-detection-barrier-0106.bin'\n",
    "    net = ie.read_network(model=license_plate_xml, weights=license_plate_bin)\n",
    "    ext = ie.load_network(network=net, device_name='CPU')\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    license_plate_images = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, (300, 300))\n",
    "        image_for_inference = np.transpose(resized_frame, (2, 0, 1))\n",
    "        image_for_inference = np.expand_dims(image_for_inference, axis=0)\n",
    "        results = ext.infer(inputs={'Placeholder': image_for_inference})\n",
    "        \n",
    "        # Retrieve the output blob\n",
    "        output_blob = next(iter(net.outputs))\n",
    "    \n",
    "        # Process the output\n",
    "        output = results[output_blob]\n",
    "        boxes = output[0][0]\n",
    "        \n",
    "        if output.shape[0] == 0:\n",
    "            print(\"No license plates detected.\")\n",
    "        else:\n",
    "            for box in boxes:\n",
    "                confidence = box[2]\n",
    "                if confidence > 0.005: \n",
    "                    # Filter detections based on confidence threshold\n",
    "                    x_min = int(box[3] * frame.shape[1])\n",
    "                    y_min = int(box[4] * frame.shape[0])\n",
    "                    x_max = int(box[5] * frame.shape[1])\n",
    "                    y_max = int(box[6] * frame.shape[0])\n",
    "                    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    license_plate_image = frame[y_min:y_max, x_min:x_max]\n",
    "                    license_plate_images.append(license_plate_image)\n",
    "        \n",
    "        cv2.imshow('License Plate Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return license_plate_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = []\n",
    "def extract_texts(image):\n",
    "    for i in range(len(image)):    \n",
    "        image_for_inference = cv2.cvtColor(image[i], cv2.COLOR_BGR2GRAY)\n",
    "        reader = easyocr.Reader(['en'],gpu=True)\n",
    "        \n",
    "        results = reader.readtext(image_for_inference)\n",
    "        for detection in results:\n",
    "                box, text, confidence = detection\n",
    "                extracted_text.append(text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_plate_images = detect_license_plates(image)\n",
    "extract_texts(license_plate_images)\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_predicted_letter(decoder_output):\n",
    "    # Define the list of supported symbols\n",
    "    supported_symbols = \"?0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "    # Get the index with the highest probability from the decoder output\n",
    "    predicted_index = np.argmax(decoder_output)\n",
    "\n",
    "    # Map the index to the corresponding symbol\n",
    "    predicted_letter = supported_symbols[predicted_index]\n",
    "\n",
    "    return predicted_letter\n",
    "\n",
    "\n",
    "text_encoder_xml = r'models\\text-recognition-0014\\text-recognition-0014.xml'\n",
    "text_encoder_bin = r'models\\text-recognition-0014\\text-recognition-0014.bin'\n",
    "net = ie.read_network(model=text_encoder_xml, weights=text_encoder_bin)\n",
    "ext = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "resized_image = cv2.resize(license_plate_images[0], (256, 64))\n",
    "image_for_inference = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "image_for_inference = np.expand_dims(image_for_inference, axis=0)\n",
    "image_for_inference = np.expand_dims(image_for_inference, axis=1)  # Add channel dimension\n",
    "\n",
    "results_encoder = ext.infer(inputs={'imgs': image_for_inference})\n",
    "decoder_hidden = results_encoder['decoder_hidden']\n",
    "features = results_encoder['features']\n",
    "\n",
    "text_decoder_xml = r'models\\text-recognition-0016\\text-recognition-0016-decoder\\text-recognition-0016-decoder.xml'\n",
    "text_decoder_bin = r'models\\text-recognition-0016\\text-recognition-0016-decoder\\text-recognition-0016-decoder.bin'\n",
    "net_decoder = ie.read_network(model=text_decoder_xml, weights=text_decoder_bin)\n",
    "ext_decoder = ie.load_network(network=net_decoder, device_name='CPU')\n",
    "\n",
    "decoder_input = np.array([0])  # Placeholder for previous predicted letter\n",
    "hidden = decoder_hidden\n",
    "text = \"\"\n",
    "\n",
    "char_dict = {symbol: i for i, symbol in enumerate(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\", start=1)}\n",
    "\n",
    "for step in range(10):\n",
    "    results_decoder = ext_decoder.infer(inputs={'decoder_input': decoder_input, 'features': features, 'hidden': hidden})\n",
    "    decoder_hidden = results_decoder['decoder_hidden']\n",
    "    decoder_output = results_decoder['decoder_output']\n",
    "    \n",
    "    # Obtain the predicted letter from the decoder output\n",
    "    predicted_letter = obtain_predicted_letter(decoder_output)\n",
    "    text += predicted_letter\n",
    "    print(predicted_letter)\n",
    "    \n",
    "    # Set decoder_input to the predicted letter index for the next time step\n",
    "    decoder_input = np.array([char_dict[predicted_letter.lower()]], dtype=np.int32)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Segmentaion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Road(video_path):\n",
    "    semantic_xml = r'models\\semantic-segmentation-adas-0001\\semantic-segmentation-adas-0001.xml'\n",
    "    semantic_bin = r'models\\semantic-segmentation-adas-0001\\semantic-segmentation-adas-0001.bin'\n",
    "    net = ie.read_network(model = semantic_xml , weights = semantic_bin)\n",
    "    ext = ie.load_network(network = net , device_name='CPU')\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    video_capture.set(cv2.CAP_PROP_BUFFERSIZE, 2) \n",
    "    \n",
    "    frame_width = int(video_capture.get(3))\n",
    "    frame_height = int(video_capture.get(4))\n",
    "    \n",
    "    size = (frame_width, frame_height)\n",
    "    writer = cv2.VideoWriter('Roadtest4.mp4', \n",
    "                         cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                         30,(800,600))\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        window_width = 800\n",
    "        window_height = 600\n",
    "        input_image = cv2.resize(frame, (2048, 1024))\n",
    "        input_image = input_image.transpose((2, 0, 1))\n",
    "        input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "\n",
    "        result = ext.infer(inputs={'data': input_image})\n",
    "\n",
    "\n",
    "        # Get the segmentation map\n",
    "        segmentation_map = result['4832.1'][0,0]\n",
    "\n",
    "        classes_of_interest = ['road','car']\n",
    "        class_names = [\n",
    "            \"road\", \"sidewalk\", \"building\", \"wall\", \"fence\", \"pole\", \"traffic light\", \"traffic sign\",\n",
    "            \"vegetation\", \"terrain\", \"sky\", \"person\", \"rider\", \"car\", \"truck\", \"bus\", \"train\",\n",
    "            \"motorcycle\", \"bicycle\", \"ego-vehicle\"\n",
    "        ]\n",
    "        # Create a mask for the classes of interest\n",
    "        mask = np.zeros_like(segmentation_map, dtype=np.uint8)\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            if class_name in classes_of_interest:\n",
    "                mask[segmentation_map == class_idx] = 255\n",
    "\n",
    "        mask = cv2.resize(mask, (window_width, window_height))\n",
    "                # Create a green mask overlay\n",
    "        frame = cv2.resize(frame,(window_width, window_height))\n",
    "        green_mask = np.zeros_like(frame)\n",
    "       \n",
    "        green_mask[:, :, 1] = mask  # Set green channel to the mask\n",
    "\n",
    "        # Overlay the green mask on the original frame\n",
    "        overlay = cv2.addWeighted(frame, 0.8, green_mask, 0.5, 0)\n",
    "        \n",
    "        cv2.imshow('License Plate Detection', overlay)\n",
    "        writer.write(overlay)\n",
    "   \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video_capture.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_path = r\"C:\\Users\\91702\\Downloads\\Travelling Along Road - Car Pov Part 2 - Pond 5 Stock Footage.mp4\"\n",
    "nn = Road(Video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(Video_path)\n",
    "window_width = 800\n",
    "window_height = 600\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "    \n",
    "size = (frame_width, frame_height)\n",
    "writer = cv2.VideoWriter('Roadtest4.mp4', \n",
    "                         cv2.VideoWriter_fourcc('F','M','P','4'),\n",
    "                         30,size)\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame,(window_width, window_height))\n",
    "    # frame = frame[400:500,:]\n",
    "    # gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # blur = cv2.blur(gray_image, (1, 1))\n",
    "    # edge = cv2.Canny(blur,20,300)\n",
    "    cv2.imshow('video',frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
