{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from openvino.inference_engine import IECore\n",
    "import tensorflow as tf\n",
    "import easyocr \n",
    "ie  = IECore()\n",
    "image_path = r'data_images\\Untitled2.png'\n",
    "image = cv2.imread(image_path)\n",
    "def show(image):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_license_plate(image):\n",
    "    license_plate_xml = r'models\\vehicle-license-plate-detection-barrier-0106\\vehicle-license-plate-detection-barrier-0106.xml'\n",
    "    license_plate_bin = r'models\\vehicle-license-plate-detection-barrier-0106\\vehicle-license-plate-detection-barrier-0106.bin'\n",
    "    net = ie.read_network(model=license_plate_xml, weights=license_plate_bin)\n",
    "    ext = ie.load_network(network=net, device_name='CPU')\n",
    "    resized_image = cv2.resize(image, (300, 300))\n",
    "    image_for_inference = np.transpose(resized_image, (2, 0, 1))\n",
    "    image_for_inference = np.expand_dims(image_for_inference, axis=0)\n",
    "    results = ext.infer(inputs={'Placeholder': image_for_inference})\n",
    "    \n",
    "    # Retrieve the output blob\n",
    "    output_blob = next(iter(net.outputs))\n",
    "\n",
    "    # Process the output\n",
    "    output = results[output_blob]\n",
    "    boxes = output[0][0]\n",
    "    license_plate_images = []\n",
    "    if output.shape[0] == 0:\n",
    "        print(\"No license plates detected.\")\n",
    "    else:\n",
    "        for box in boxes:\n",
    "            confidence = box[2]\n",
    "            if confidence > 0.005: \n",
    "                # Filter detections based on confidence threshold\n",
    "                x_min = int(box[3] * image.shape[1])\n",
    "                y_min = int(box[4] * image.shape[0])\n",
    "                x_max = int(box[5] * image.shape[1])\n",
    "                y_max = int(box[6] * image.shape[0])\n",
    "                cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                license_plate_image = image[y_min:y_max, x_min:x_max]\n",
    "                license_plate_images.append(license_plate_image)\n",
    "                \n",
    "    return license_plate_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_plate_images = detect_license_plate(image)\n",
    "image_for_inference = cv2.cvtColor(license_plate_images[0], cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(image_for_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "extracted_text = []\n",
    "results = reader.readtext(image_for_inference)\n",
    "for detection in results:\n",
    "        box, text, confidence = detection\n",
    "        extracted_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50 107024']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 0, 31, 0, 28, 0, 16, 0]\n"
     ]
    }
   ],
   "source": [
    "text_encoder_xml = r'models\\text-recognition-0014\\text-recognition-0014.xml'\n",
    "text_encoder_bin = r'models\\text-recognition-0014\\text-recognition-0014.bin'\n",
    "net = ie.read_network(model=text_encoder_xml, weights=text_encoder_bin)\n",
    "ext = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "resized_image = cv2.resize(image, (128, 32))\n",
    "image_for_inference = np.expand_dims(resized_image, axis=0)\n",
    "image_for_inference = np.expand_dims(image_for_inference, axis=1) \n",
    "image_for_inference = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "results = ext.infer(inputs={'imgs': image_for_inference})\n",
    "Blob = results['logits']\n",
    "\n",
    "blob = Blob.reshape(-1, 1, 37)  # Reshape to (W, B, L)\n",
    "\n",
    "beam_width = 5  # Beam width for the decoder\n",
    "top_paths = 1  # Number of top paths to retrieve\n",
    "\n",
    "decoded_sparse = tf.nn.ctc_beam_search_decoder(inputs=blob, sequence_length=[blob.shape[0]], beam_width=beam_width, top_paths=top_paths)\n",
    "decoded_text = tf.sparse.to_dense(decoded_sparse[0][0]).numpy().tolist()\n",
    "print(decoded_text[0])\n",
    "mapping = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "decoded_text = ''.join([mapping[i] for i in decoded_text[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g0v0s0g0'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got an unexpected keyword argument 'merge_repeated'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m top_paths \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# Number of top paths to retrieve\u001b[39;00m\n\u001b[0;32m      6\u001b[0m merge_repeated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# Whether to merge repeated characters\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m decoded_sparse \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mctc_beam_search_decoder(inputs\u001b[39m=\u001b[39;49mblob, sequence_length\u001b[39m=\u001b[39;49m[blob\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]], beam_width\u001b[39m=\u001b[39;49mbeam_width, top_paths\u001b[39m=\u001b[39;49mtop_paths, merge_repeated\u001b[39m=\u001b[39;49mmerge_repeated)\n\u001b[0;32m      8\u001b[0m decoded_text \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mto_dense(decoded_sparse[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      9\u001b[0m decoded_text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mchr\u001b[39m(\u001b[39mint\u001b[39m(i)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m decoded_text])\n",
      "File \u001b[1;32mc:\\Users\\91702\\OneDrive\\Desktop\\OpenVIno\\openvino_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\91702\\OneDrive\\Desktop\\OpenVIno\\openvino_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1170\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[39mif\u001b[39;00m iterable_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m   args, kwargs \u001b[39m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[1;32m-> 1170\u001b[0m result \u001b[39m=\u001b[39m api_dispatcher\u001b[39m.\u001b[39;49mDispatch(args, kwargs)\n\u001b[0;32m   1171\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1172\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: Got an unexpected keyword argument 'merge_repeated'"
     ]
    }
   ],
   "source": [
    "def obtain_predicted_letter(decoder_output):\n",
    "    # Define the list of supported symbols\n",
    "    supported_symbols = \"?0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "    # Get the index with the highest probability from the decoder output\n",
    "    predicted_index = np.argmax(decoder_output)\n",
    "\n",
    "    # Map the index to the corresponding symbol\n",
    "    predicted_letter = supported_symbols[predicted_index]\n",
    "\n",
    "    return predicted_letter\n",
    "\n",
    "\n",
    "text_encoder_xml = r'models\\text-recognition-0014\\text-recognition-0014.xml'\n",
    "text_encoder_bin = r'models\\text-recognition-0014\\text-recognition-0014.bin'\n",
    "net = ie.read_network(model=text_encoder_xml, weights=text_encoder_bin)\n",
    "ext = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "resized_image = cv2.resize(license_plate_images[0], (256, 64))\n",
    "image_for_inference = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "image_for_inference = np.expand_dims(image_for_inference, axis=0)\n",
    "image_for_inference = np.expand_dims(image_for_inference, axis=1)  # Add channel dimension\n",
    "\n",
    "results_encoder = ext.infer(inputs={'imgs': image_for_inference})\n",
    "decoder_hidden = results_encoder['decoder_hidden']\n",
    "features = results_encoder['features']\n",
    "\n",
    "text_decoder_xml = r'models\\text-recognition-0016\\text-recognition-0016-decoder\\text-recognition-0016-decoder.xml'\n",
    "text_decoder_bin = r'models\\text-recognition-0016\\text-recognition-0016-decoder\\text-recognition-0016-decoder.bin'\n",
    "net_decoder = ie.read_network(model=text_decoder_xml, weights=text_decoder_bin)\n",
    "ext_decoder = ie.load_network(network=net_decoder, device_name='CPU')\n",
    "\n",
    "decoder_input = np.array([0])  # Placeholder for previous predicted letter\n",
    "hidden = decoder_hidden\n",
    "text = \"\"\n",
    "\n",
    "char_dict = {symbol: i for i, symbol in enumerate(\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\", start=1)}\n",
    "\n",
    "for step in range(10):\n",
    "    results_decoder = ext_decoder.infer(inputs={'decoder_input': decoder_input, 'features': features, 'hidden': hidden})\n",
    "    decoder_hidden = results_decoder['decoder_hidden']\n",
    "    decoder_output = results_decoder['decoder_output']\n",
    "    \n",
    "    # Obtain the predicted letter from the decoder output\n",
    "    predicted_letter = obtain_predicted_letter(decoder_output)\n",
    "    text += predicted_letter\n",
    "    print(predicted_letter)\n",
    "    \n",
    "    # Set decoder_input to the predicted letter index for the next time step\n",
    "    decoder_input = np.array([char_dict[predicted_letter.lower()]], dtype=np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
